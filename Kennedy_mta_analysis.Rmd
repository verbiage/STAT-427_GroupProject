---
title: "MTA Ridership Project"
output: html_notebook
---

```{r setup, warning=FALSE, message=FALSE}
library(tidyverse)
library(splines)
library(glmnet)
library(readr)
library(dplyr)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
library(ggplot2)

options(scipen = 999)
```


```{r}

url <- "https://data.ny.gov/api/views/vxuj-8kew/rows.csv?accessType=DOWNLOAD"
df<- read_csv(url)
# df <- read_csv("MTA_Daily_Ridership_Data.csv")
glimpse(df)
colnames(df)

```

Preparing Data: Regression Section
```{r}
response_var <- "Subways: Total Estimated Ridership"
predictor_vars <- c("Buses: Total Estimated Ridership", 
                    "LIRR: Total Estimated Ridership", 
                    "Metro-North: Total Estimated Ridership",
                    "Access-A-Ride: Total Scheduled Trips", 
                    "Bridges and Tunnels: Total Traffic", 
                    "Staten Island Railway: Total Estimated Ridership")

df_clean <- na.omit(df[, c(response_var, predictor_vars)])

# Create matrices
x <- as.matrix(df_clean[, predictor_vars])
y <- df_clean[[response_var]]

# Train/Test Split
set.seed(168)
train_indices <- sample(1:nrow(x), 0.8 * nrow(x))
x_train <- x[train_indices, ]
y_train <- y[train_indices]
x_test  <- x[-train_indices, ]
y_test  <- y[-train_indices]

```
Ridge and Lasso Regression
```{r}
# Ridge
ridge_model <- cv.glmnet(x_train, y_train, alpha = 0)
ridge_pred <- predict(ridge_model, s = ridge_model$lambda.min, newx = x_test)
ridge_mse <- mean((ridge_pred - y_test)^2)

# Lasso
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1)
lasso_pred <- predict(lasso_model, s = lasso_model$lambda.min, newx = x_test)
lasso_mse <- mean((lasso_pred - y_test)^2)

cat("Ridge MSE:", ridge_mse, "\n")
cat("Lasso MSE:", lasso_mse, "\n")

```

Ridge vs Lasso: Predicted vs Actual Plot
```{r}
# Plotting
ridge_plot_df <- data.frame(Actual = y_test, Predicted = as.numeric(ridge_pred), Model = "Ridge")
lasso_plot_df <- data.frame(Actual = y_test, Predicted = as.numeric(lasso_pred), Model = "Lasso")
all_predictions_df <- rbind(ridge_plot_df, lasso_plot_df)

ggplot(all_predictions_df, aes(x = Actual, y = Predicted, color = Model)) +
  geom_point(alpha = 0.7) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(
    title = "Predicted vs Actual Subway Ridership",
    x = "Actual Ridership",
    y = "Predicted Ridership",
    color = "Model"
  ) +
  theme_minimal()

```

Ridge/Lasso CV Plots
```{r}
library(ggplot2)

# Create data frames for ridge and lasso
ridge_df <- data.frame(
  log_lambda = log(ridge_model$lambda),
  mse_mean = ridge_model$cvm,
  mse_upper = ridge_model$cvup,
  mse_lower = ridge_model$cvlo
)

lasso_df <- data.frame(
  log_lambda = log(lasso_model$lambda),
  mse_mean = lasso_model$cvm,
  mse_upper = lasso_model$cvup,
  mse_lower = lasso_model$cvlo
)

ridge_df <- ridge_df %>% mutate(across(c(mse_mean, mse_upper, mse_lower), ~ .x / 1e9))
lasso_df <- lasso_df %>% mutate(across(c(mse_mean, mse_upper, mse_lower), ~ .x / 1e9))

# Ridge plot
ridge_plot <- ggplot(ridge_df, aes(x = log_lambda, y = mse_mean)) +
  geom_point(color = "red", size = 2) +
  geom_errorbar(aes(ymin = mse_lower, ymax = mse_upper), width = 0.05, color = "gray") +
  labs(title = "Ridge: CV MSE vs Lambda", 
       x = expression(log(lambda)), 
       y = "Mean-Squared Error (Billions)") +
  scale_y_continuous(labels = scales::comma) +  # <-- nice labels: 0, 200, 400
  theme_minimal(base_size = 14) # slightly larger base font

# Lasso plot
lasso_plot <- ggplot(lasso_df, aes(x = log_lambda, y = mse_mean)) +
  geom_point(color = "red", size = 2) +
  geom_errorbar(aes(ymin = mse_lower, ymax = mse_upper), width = 0.05, color = "gray") +
  labs(title = "Lasso: CV MSE vs Lambda", 
       x = expression(log(lambda)), 
       y = "Mean-Squared Error (Billions)") +
  scale_y_continuous(labels = scales::comma) +
  theme_minimal(base_size = 14)

grid.arrange(ridge_plot, lasso_plot, ncol = 2)


```

Classification: Decision Tree and Random Forest

```{r}
# Create categorical target variable
quantiles <- quantile(df_clean[[response_var]], probs = c(0.33, 0.66))
df_clean$ridership_class <- cut(df_clean[[response_var]],
                                breaks = c(-Inf, quantiles, Inf),
                                labels = c("Low", "Medium", "High"),
                                right = TRUE)

# Class distribution
table(df_clean$ridership_class)


```

```{r}
# Train/Test split for classification
set.seed(168)
train_index <- createDataPartition(df_clean$ridership_class, p = 0.8, list = FALSE)

train_data <- df_clean[train_index, ]
test_data  <- df_clean[-train_index, ]

# Clean column names (no colons/spaces)
train_data_clean <- train_data %>%
  rename_with(~ gsub("[^[:alnum:]_]", "_", .))

test_data_clean <- test_data %>%
  rename_with(~ gsub("[^[:alnum:]_]", "_", .))

```

Training Decision Tree
```{r}
tree_model <- rpart(ridership_class ~ Buses__Total_Estimated_Ridership +
                                    LIRR__Total_Estimated_Ridership +
                                    Metro_North__Total_Estimated_Ridership +
                                    Access_A_Ride__Total_Scheduled_Trips +
                                    Bridges_and_Tunnels__Total_Traffic +
                                    Staten_Island_Railway__Total_Estimated_Ridership,
                    data = train_data_clean,
                    method = "class",
                    control = rpart.control(maxdepth = 5, minsplit = 30))

# Checking the complexity parameter to prune
printcp(tree_model)


# Pruning
pruned_tree <- prune(tree_model, cp = tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"])

rpart.plot(pruned_tree, type = 2, extra = 104, fallen.leaves = TRUE)


```




Train Random Forest
```{r}
rf_model <- randomForest(ridership_class ~ Buses__Total_Estimated_Ridership +
                                          LIRR__Total_Estimated_Ridership +
                                          Metro_North__Total_Estimated_Ridership +
                                          Access_A_Ride__Total_Scheduled_Trips +
                                          Bridges_and_Tunnels__Total_Traffic +
                                          Staten_Island_Railway__Total_Estimated_Ridership,
                         data = train_data_clean,
                         ntree = 500,
                         importance = TRUE)

print(rf_model)

```

Evaluating Tree and RF
```{r}
tree_pred <- predict(tree_model, test_data_clean, type = "class")
rf_pred   <- predict(rf_model, test_data_clean)

# Confusion Matrices
cat("Decision Tree Confusion Matrix:\n")
print(confusionMatrix(tree_pred, test_data_clean$ridership_class))

cat("\nRandom Forest Confusion Matrix:\n")
print(confusionMatrix(rf_pred, test_data_clean$ridership_class))

```
Variable Importance (Random Forest)
```{r}
importance(rf_model)

```
```{r}
rf_importance <- importance(rf_model)
rf_importance_df <- data.frame(Feature = rownames(rf_importance), Importance = rf_importance[,1])
rf_importance_df <- rf_importance_df[order(-rf_importance_df$Importance),]

ggplot(rf_importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(title = "Random Forest Feature Importance", x = "Feature", y = "Importance") +
  theme_minimal()

```


Accuracy
```{r}
tree_accuracy <- sum(tree_pred == test_data_clean$ridership_class) / length(tree_pred)
rf_accuracy <- sum(rf_pred == test_data_clean$ridership_class) / length(rf_pred)

cat(sprintf("Decision Tree Accuracy: %.2f%%\n", tree_accuracy * 100))
cat(sprintf("Random Forest Accuracy: %.2f%%\n", rf_accuracy * 100))

```

Cross-Validation: K-Fold CV for Decision Trees
```{r}
set.seed(168)
train_control <- trainControl(method = "cv", number = 10)

# Train CV Tree model
tree_cv_model <- train(ridership_class ~ Buses__Total_Estimated_Ridership +
                                    LIRR__Total_Estimated_Ridership +
                                    Metro_North__Total_Estimated_Ridership +
                                    Access_A_Ride__Total_Scheduled_Trips +
                                    Bridges_and_Tunnels__Total_Traffic +
                                    Staten_Island_Railway__Total_Estimated_Ridership,
                       data = train_data_clean,
                       method = "rpart",
                       trControl = train_control)

# CV Model Summary
print(tree_cv_model)

# Predict using CV model
tree_pred_cv <- predict(tree_cv_model, test_data_clean)

# Confusion Matrix
cat("Decision Tree (CV) Confusion Matrix:\n")
print(confusionMatrix(tree_pred_cv, test_data_clean$ridership_class))

```


